Ocular can recognize collections of documents that use historical fontsThe system works best when you run it on a collection of documents thamainly uses a single font (e.g. a whole book). Ocular works in two phases//////////////////////////////////////////////////////////////////////////Phase 1: Train a font model for your particular collection of documentOcular is unsupervised, so you don't need document images that arlabeled with human transcriptions in order to learn the font. InsteadOcular learns the font directly, straight from the set of input documenimages. Since the system often only needs a small portion of a book (othe order of 10 pages) to effectively learn the font, it is usually mosefficient to learn the font from a subset of your document collection. Sothe first step is to select about 10 document images from your collectiothat are relatively clean (no weird formatting, and minimal scanninnoise). Put these document images togther in a directory. Run thfollowing command from within the ocular directory in order to learn font model-outputPath output_path -outputFontPath output_font_patHere, 'selected_images_path' is the path to the directory where you puyour selected document images, 'output_path' is a directory where thoutput transcriptions (useful for checking whether you've effectivellearned the font) and images of the line extractions (useful to see ithe pre-processing phase was effective) will be written, an'output_font_path' is the path of the file that will contain the learnefont modelThe directory './test' contains several images of historical documentthat can be used to test Ocular. Simply run the command above wit'-inputPath' set to './test'.//////////////////////////////////////////////////////////////////////////Phase 2: Transcribe your full document collection using the learned fonNow that you've learned a font model (the one that was written t'output_font_path' in phase 1) you can transcribe your full collection ofdocument images. In order to perform the full transcription, run thfollowing command from within the ocular directory-inputPath all_images_path -outputPath output_patHere, 'output_font_path' is the path to the font model you produced inphase 1, 'all_images_path' is a path to the directory containing all thimages in your document collection, and 'output_path' specifies the pathto a directory where you want to store the output transcriptions and thline extraction images for each document//////////////////////////////////////////////////////////////////////////Configuration parametersIn order to print the full list of options for running Ocular use thfollowing commandjava -jar ocular.jar -hel//////////////////////////////////////////////////////////////////////////Important configuration parameters that affect accuracyAn important option that can be specified is the choice of language modelThe 'lm' directory contains several language model files'./lm/nyt.lmser-Trained on New York Times data'./lm/nyt_longs.lmser-Trained on New York Times data-Uses long s character, suitable for documents that use the long s glyph'./lm/ob.lmser-Trained on Old Bailey historical court proceedings'./lm/ob_longs.lmser-Trained on Old Bailey historical court proceedings-Uses long s character, suitable for documents that use the long s glyphThe language model used by Ocular is specified by the 'lmPath' parameterwhich can either be set from the command line with '-lmPath' or modifiein the configuration file './conf/base.conf'. The default setting othis parameter is './lm/nyt.lmser'Another important option is the threshold for binarizing the input imageinto black and white pixels. This option is specified with th'binarizeThreshold' parameter, again either on the command line, or directlin the configuration file. It can be set to real numbers between 0 and 1and has a default value of 0.12. If you notice that the line extractioimages in the output folder look over-exposed (too much white), try raisinthe binarization threshold. This can improve accuracy//////////////////////////////////////////////////////////////////////////Important configuration parameters that affect speedOcular can be computationally intensive to run. It requires a machinwith at least 8GB of RAM, and can benefit from more advanced hardware lika discrete GPU.On a high-end modern desktop computer, Ocular should take approximatel1 minute per page during the transcription phase (phase 2). On an oldelaptop, Ocular may take as much as 10 minutes per page during the samphaseIt is possible to run Ocular in a fast mode that sacrifies a small amounof transcription accuracy in order to increase speed. In order to run ithis mode replace every mention of the '++conf/base.conf' configuratiofile with '++conf/fast.conf' in the description of phase 1 and phase aboveIt is also possible to substantially speed up Ocular without sacrificinaccuracy by making better use of available hardware. If you are runninon an Apple laptop try setting the 'emissionEngine' parameter t'OPENCL'. This can be done either with the command line fla'-emissionEngine' or from within the configuration file. This option wilmake use of the integrated GPU where possible, and make more efficienuse of the processor otherwise. Specifically, using the following commandfor phase 1 and phase 2Phase 1selected_images_path -outputPath output_path -outputFontPath output_font_patPhase 2output_font_path -inputPath all_images_path -outputPath output_patIf you are not using an Apple machine, the 'OPENCL' option may still bused if you first install OpenCL. Instructions for how to do this can bfound onlineFinally, if you have a discrete NVIDIA GPU, Ocular can be sped up evemore. You need to make sure CUDA is installed, and then se'emissionEngine' to 'CUDA'. You may need to add the corresponding JCudDLL to your dynamic library path when you run the java command. The DLLare included in the './lib' directory. Choose the one that correspondto your operating system//////////////////////////////////////////////////////////////////////////Text line extractionOCR usually has two steps: 1) extract images of isolated lines of text frothe input image, 2) recognize each line image. Strictly speaking, Oculais a text line recognizerThe line extractor Ocular uses is kind of rudimentary and can only handldocuments without complex formatting (i.e. only a single column of text)It should, however, be pretty robust to noise and may even perform well obook images that contain some of the opposing page in the margin. The wato check whether something did go wrong in the line extraction phase is tlook at the line extraction images in the output directory. If these don'contain a sequence of images, each of which contains a single line of textsomething went wrongIf something does go wrong here, there are several possible solutions. Onsolution is to manually crop your images ahead of time (not into individualines, just into big blocks of text). But that can be time consuming. better option is something we're working on right now and will release ian update to Ocular. The open source OCR library called Ocropus contains high quality line extractor. In a future release you will have the optioto use the Ocropus line extractor from within our historical recognizerThis way you'd get the best of both worlds: a great historical texrecognizer and a line extractor that can handle more complicateformatting//////////////////////////////////////////////////////////////////////////LicenseCopyright (c) 2013 Taylor Berg-Kirkpatrick and Greg Durrett. All RightReservedThis program is free software: you can redistribute it and/or modifit under the terms of the GNU General Public License as published bthe Free Software Foundation, either version 3 of the License, o(at your option) any later versionThis program is distributed in the hope that it will be usefulbut WITHOUT ANY WARRANTY; without even the implied warranty oMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See thGNU General Public License for more detailsYou should have received a copy of the GNU General Public Licensalong with this program.  If not, see <http://www.gnu.org/licenses/>//////////////////////////////////////////////////////////////////////////Update Log2014-8-2--Preliminary version
